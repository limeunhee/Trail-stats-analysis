{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Scraping trail information from Alltrails.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 uses three .py files in order to scrape trail information from Alltrails.com. In the src folder, there are 3 .py files that are needed to scrape trail informations. Each .py file utilizes python multiprocessing tool to parallelize scraping processes, that can be executed in terminal or jupyter notebook.\n",
    "\n",
    "1. 'get_state_html.py' : User can specify list of states to scrape alltrails information from. Exicuting this .py file will save .html file that contains urls to individual trail page in each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabama\n",
      "arizona\n",
      "california\n",
      "connecticut\n",
      "florida\n",
      "hawaii\n",
      "illinois\n",
      "iowa\n",
      "kansas\n",
      "alaska\n",
      "idaho\n",
      "kentucky\n",
      "indiana\n",
      "maine\n",
      "louisiana\n",
      "delaware\n",
      "georgia\n",
      "arkansas\n",
      "colorado\n",
      "massachusetts\n",
      "minnesota\n",
      "missouri\n",
      "nebraska\n",
      "new-hampshire\n",
      "nevada\n",
      "mississippi\n",
      "maryland\n",
      "new-mexico\n",
      "north-carolina\n",
      "ohio\n",
      "michigan\n",
      "oregon\n",
      "montana\n",
      "new-jersey\n",
      "rhode-island\n",
      "new-york\n",
      "oklahoma\n",
      "south-carolina\n",
      "north-dakota\n",
      "south-dakota\n",
      "texas\n",
      "vermont\n",
      "pennsylvania\n",
      "tennessee\n",
      "washington\n",
      "wisconsin\n",
      "virginia\n",
      "wyoming\n",
      "utah\n",
      "west-virginia\n"
     ]
    }
   ],
   "source": [
    "!python get_state_html.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 'get_trail_urls.py' : User will use .html files from step 1, to extract each trail url that can be used to scrape information on each trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohio\n",
      "oregon\n",
      "illinois\n",
      "mississippi\n",
      "tennessee\n",
      "minnesota\n",
      "south-carolina\n",
      "utah\n",
      "nevada\n",
      "new-hampshire\n",
      "montana\n",
      "florida\n",
      "north-carolina\n",
      "new-york\n",
      "new-jersey\n",
      "louisiana\n",
      "rhode-island\n",
      "oklahoma\n",
      "west-virginia\n",
      "delaware\n",
      "north-dakota\n",
      "kentucky\n",
      "washington\n",
      "michigan\n",
      "indiana\n",
      "vermont\n",
      "connecticut\n",
      "maryland\n",
      "virginia\n",
      "new-mexico\n",
      "alabama\n",
      "arkansas\n",
      "south-dakota\n",
      "iowa\n",
      "kansas\n",
      "colorado\n",
      "missouri\n",
      "pennsylvania\n",
      "maine\n",
      "california\n",
      "alaska\n",
      "hawaii\n",
      "wyoming\n",
      "wisconsin\n",
      "texas\n",
      "massachusetts\n",
      "arizona\n",
      "georgia\n",
      "idaho\n",
      "nebraska\n",
      "CPU times: user 1.24 s, sys: 388 ms, total: 1.63 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python get_trail_urls.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 'get_trail_information.py': Using url's from step 2, information on all trails from each state is scraped and saved to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eunheelim/Capstone1/url2/oklahoma.txt\n",
      "oklahoma:50\n",
      "oklahoma:100\n",
      "oklahoma:150\n",
      "oklahoma:200\n",
      "oklahoma:250\n",
      "oklahoma:300\n",
      "CPU times: user 20.1 s, sys: 7.09 s, total: 27.1 s\n",
      "Wall time: 9min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python get_trail_information.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eunheelim/Capstone1/url2/colorado.txt\n",
      "colorado:50\n",
      "colorado:100\n",
      "colorado:150\n",
      "colorado:200\n",
      "colorado:250\n",
      "colorado:300\n",
      "colorado:350\n",
      "colorado:400\n",
      "colorado:450\n",
      "colorado:500\n",
      "colorado:550\n",
      "colorado:600\n",
      "colorado:650\n",
      "colorado:700\n",
      "colorado:750\n",
      "colorado:800\n",
      "colorado:850\n",
      "colorado:900\n",
      "colorado:950\n",
      "colorado:1000\n",
      "CPU times: user 40.5 s, sys: 14.1 s, total: 54.6 s\n",
      "Wall time: 21min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python get_trail_information.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
